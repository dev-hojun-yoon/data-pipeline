version: '3.8'

networks:
  hadoop-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  zookeeper-1-data:
  zookeeper-1-logs:
  kafka-1-data:
  mongodb-1-data:
  mongodb-1-config:
  spark-master-logs:

services:
  # Zookeeper 클러스터 - Node 1 (Single node for the cluster)
  zookeeper-1:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper-1
    container_name: zookeeper-1
    ports:
      - "2189:2189"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2189
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SERVER_ID: 1
      # Standalone Zookeeper, no other servers
      ZOOKEEPER_SERVERS: zookeeper-1:2888:3888
    volumes:
      - zookeeper-1-data:/var/lib/zookeeper/data
      - zookeeper-1-logs:/var/lib/zookeeper/log
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.10
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2189"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Kafka 브로커 1
  kafka-1:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka-1
    container_name: kafka-1
    depends_on:
      zookeeper-1:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: '192.168.0.12:2189'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: EXTERNAL://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: EXTERNAL://192.168.0.12:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: EXTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      KAFKA_MIN_IN_SYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
    volumes:
      - kafka-1-data:/var/lib/kafka/data
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.11
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka-1
    ports:
      - "3030:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: hadoop-kafka-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: 192.168.0.12:9092,192.168.0.13:9093
      KAFKA_CLUSTERS_0_ZOOKEEPER: 192.168.0.12:2189
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.12
    restart: unless-stopped

  # MongoDB Primary
  mongodb-1:
    image: mongo:7.0
    hostname: mongodb-1
    container_name: mongodb-1
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password123
      MONGO_INITDB_DATABASE: financial_db
    volumes:
      - mongodb-1-data:/data/db
      - mongodb-1-config:/data/configdb
      - ./scripts/mongo-keyfile:/etc/mongo/mongo-keyfile:ro
      - ./scripts/init-replica.js:/docker-entrypoint-initdb.d/init-replica.js:ro
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.13
    extra_hosts:
      - "mongodb-2:192.168.0.13"
      - "mongodb-arbiter:192.168.0.13"
    command: >
      bash -c "
        # 키파일 권한 설정
        if [ -f /etc/mongo/mongo-keyfile ]; then
          chmod 400 /etc/mongo/mongo-keyfile
          chown mongodb:mongodb /etc/mongo/mongo-keyfile
        fi
        
        # 데이터 디렉토리가 비어있는지 확인 (첫 실행인지)
        if [ ! -f /data/db/.mongodb_initialized ]; then
          echo 'First time setup - starting without authentication'
          # 첫 실행시에는 인증 없이 시작
          mongod --bind_ip_all --port 27017 &
          MONGO_PID=\$!
          
          # MongoDB가 준비될 때까지 대기
          echo 'Waiting for MongoDB to start...'
          until mongosh --port 27017 --eval 'db.runCommand({ping: 1})' > /dev/null 2>&1; do
            sleep 2
          done
          
          echo 'Creating admin user...'
          mongosh --port 27017 --eval \"
            db.getSiblingDB('admin').createUser({
              user: '${MONGO_INITDB_ROOT_USERNAME}',
              pwd: '${MONGO_INITDB_ROOT_PASSWORD}',
              roles: [{ role: 'root', db: 'admin' }]
            });
          \"
          
          echo 'Creating application database and user...'
          mongosh --port 27017 --eval \"
            db.getSiblingDB('${MONGO_INITDB_DATABASE}').createUser({
              user: 'app_user',
              pwd: 'app_password',
              roles: [{ role: 'readWrite', db: '${MONGO_INITDB_DATABASE}' }]
            });
          \"
          
          # 초기화 완료 표시
          touch /data/db/.mongodb_initialized
          
          # MongoDB 종료
          echo 'Shutting down MongoDB...'
          mongosh --port 27017 --eval 'db.getSiblingDB(\"admin\").shutdownServer()' || true
          wait \$MONGO_PID
        fi
        
        echo 'Starting MongoDB with authentication and replica set...'
        if [ -f /etc/mongo/mongo-keyfile ]; then
          exec mongod --replSet rs0 --bind_ip_all --auth --keyFile /etc/mongo/mongo-keyfile
        else
          exec mongod --replSet rs0 --bind_ip_all --auth
        fi
      "
    healthcheck:
      test: ["CMD", "mongosh", "--port", "27017", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # Spark Master
  spark-master:
    image: bitnami/spark:3.5
    hostname: spark-master
    container_name: spark-master
    ports:
      - "8081:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    volumes:
      - spark-master-logs:/opt/bitnami/spark/logs
      - ./spark-jobs:/opt/spark-jobs
      - ./spark-libs:/opt/spark-libs
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.14
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped


  # Spark Job Submitter - HDFS에서 데이터 읽기 및 Kafka 전송
  spark-submit-job:
    image: bitnami/spark:3.5
    container_name: spark-submit-job
    depends_on:
      - spark-master
      - kafka-1
    environment:
      - SPARK_MODE=submit
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_SUBMIT_ARGS=--class DataPipelineJob --master spark://spark-master:7077 --deploy-mode client
    volumes:
      - ./spark_producer.py:/app/spark_producer.py
      - ./spark-libs:/opt/spark-libs
      - ./hadoop-conf/core-site.xml:/etc/hadoop/core-site.xml
      - ./logs:/app/logs
      - ./log4j.properties:/etc/spark/log4j.properties
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.15
    command: >
      bash -c "
        sleep 60 &&
        spark-submit 
          --class com.hadoop.pipeline.DataPipelineJob
          --master spark://spark-master:7077
          --deploy-mode client
          --driver-memory 1g
          --executor-memory 1g
          --executor-cores 2
          --jars /opt/spark-libs/kafka-clients-3.5.0.jar,/opt/spark-libs/spark-sql-kafka-0-10_2.12-3.5.0.jar,/opt/spark-libs/hadoop-client-3.3.4.jar
          --files /etc/hadoop/core-site.xml,/etc/spark/log4j.properties
          --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/etc/spark/log4j.properties
          --conf spark.executor.extraJavaOptions=-Dlog4j.configuration=file:/etc/spark/log4j.properties
          --kafka-bootstrap-servers 192.168.0.12:9092,192.168.0.13:9093
          /app/spark_producer.py --json-file /input/test.json
      "
    restart: unless-stopped

  # Kafka to MongoDB Consumer
  kafka-mongo-consumer:
    build:
      context: .
      dockerfile: Dockerfile.consumer
    container_name: kafka-mongo-consumer
    depends_on:
      - kafka-1
      - mongodb-1
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=192.168.0.12:9092,192.168.0.13:9093
      - MONGO_HOST=mongodb
      - MONGO_PORT=27017
      - MONGO_DB=financial_db
      - MONGO_USER=admin
      - MONGO_PASSWORD=admin123
      - BATCH_SIZE=100
    volumes:
      - ./consumer-app:/app
    working_dir: /app
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.16
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "pgrep", "-f", "KafkaMongoConsumer"]
      interval: 30s
      timeout: 10s
      retries: 3