version: '3.8'

networks:
  hadoop-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  zookeeper-1-data:
  zookeeper-1-logs:
  kafka-1-data:
  mongodb-1-data:
  mongodb-1-config:
  spark-master-logs:

services:
  # Zookeeper 클러스터 - Node 1 (Single node for the cluster)
  zookeeper-1:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper-1
    container_name: zookeeper-1
    ports:
      - "2189:2189"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2189
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SERVER_ID: 1
      # Standalone Zookeeper, no other servers
      ZOOKEEPER_SERVERS: zookeeper-1:2888:3888
    volumes:
      - zookeeper-1-data:/var/lib/zookeeper/data
      - zookeeper-1-logs:/var/lib/zookeeper/log
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.10
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2189"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Kafka 브로커 1
  kafka-1:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka-1
    container_name: kafka-1
    depends_on:
      zookeeper-1:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: '192.168.0.12:2189'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: EXTERNAL://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: EXTERNAL://192.168.0.12:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: EXTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      KAFKA_MIN_IN_SYNC_REPLICAS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
    volumes:
      - kafka-1-data:/var/lib/kafka/data
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.11
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka-1
    ports:
      - "3030:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: hadoop-kafka-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: 192.168.0.12:9092,192.168.0.13:9093
      KAFKA_CLUSTERS_0_ZOOKEEPER: '192.168.0.12:2189'
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.12
    restart: unless-stopped

  # MongoDB Primary
  mongodb-1:
    image: mongo:7.0
    hostname: mongodb-1
    container_name: mongodb-1
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password123
      MONGO_INITDB_DATABASE: financial_db
    volumes:
      - mongodb-1-data:/data/db
      - mongodb-1-config:/data/configdb
      - ./scripts/mongo-keyfile:/etc/mongo/mongo-keyfile
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.13
    command:
      - /bin/bash
      - -c
      - |
        # 키파일 권한 설정
        if [ -f /etc/mongo/mongo-keyfile ]; then
          chmod 400 /etc/mongo/mongo-keyfile
          chown mongodb:mongodb /etc/mongo/mongo-keyfile
        fi
        
        # 첫 실행인지 확인
        if [ ! -f /data/db/.mongodb_initialized ]; then
          echo 'First time setup - starting without authentication'
          mongod --bind_ip_all --port 27017 & 
          MONGO_PID=$${!} 
          
          # MongoDB 준비 대기
          echo 'Waiting for MongoDB to start...'
          until mongosh --port 27017 --eval 'db.runCommand({ping: 1})' > /dev/null 2>&1; do
            sleep 2
          done
          
          echo 'Creating admin user...'
          mongosh --port 27017 --eval "db.getSiblingDB('admin').createUser({user: '$${MONGO_INITDB_ROOT_USERNAME}', pwd: '$${MONGO_INITDB_ROOT_PASSWORD}', roles: [{role: 'root', db: 'admin'}]})"
          
          echo 'Creating application database and user...'
          mongosh --port 27017 --eval "db.getSiblingDB('$${MONGO_INITDB_DATABASE}').createUser({user: 'app_user', pwd: 'app_password', roles: [{role: 'readWrite', db: '$${MONGO_INITDB_DATABASE}'}]})"

          echo 'Forcing database creation by creating a placeholder collection...'
          mongosh --port 27017 --eval "db.getSiblingDB('$${MONGO_INITDB_DATABASE}').createCollection('placeholder')"
          
          # 초기화 완료 표시
          touch /data/db/.mongodb_initialized
          
          # MongoDB 종료 (인증 사용)
          echo 'Shutting down MongoDB with authentication...'
          mongosh --port 27017 -u '$${MONGO_INITDB_ROOT_USERNAME}' -p '$${MONGO_INITDB_ROOT_PASSWORD}' --authenticationDatabase 'admin' --eval 'db.getSiblingDB("admin").shutdownServer()' || true
          wait $${MONGO_PID}
        fi
        
        echo 'Starting MongoDB with replica set (waiting for other nodes)...'
        # 레플리카셋 모드로 시작하되, 초기화는 나중에
        if [ -f /etc/mongo/mongo-keyfile ]; then
          exec mongod --replSet rs0 --bind_ip_all --auth --keyFile /etc/mongo/mongo-keyfile
        else
          exec mongod --replSet rs0 --bind_ip_all --auth
        fi
    healthcheck:
      test: ["CMD", "mongosh", "--port", "27017", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # Spark Master
  spark-master:
    image: bitnami/spark:3.5
    hostname: spark-master
    container_name: spark-master
    ports:
      - "8081:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    volumes:
      - spark-master-logs:/opt/bitnami/spark/logs
      - ./spark-jobs:/opt/spark-jobs
      - ./spark-libs:/opt/spark-libs
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.14
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped


  # Spark Job Submitter - HDFS에서 데이터 읽기 및 Kafka 전송
  spark-submit-job:
    image: bitnami/spark:3.5
    container_name: spark-submit-job
    depends_on:
      - spark-master
      - kafka-1
    environment:
      - SPARK_MODE=submit
      - SPARK_MASTER_URL=spark://spark-master:7077
      - HADOOP_USER_NAME=hadoop
      - SPARK_SUBMIT_ARGS=--class DataPipelineJob --master spark://spark-master:7077 --deploy-mode client
    volumes:
      - ./spark_producer.py:/app/spark_producer.py
      - ./spark-libs:/opt/spark-libs
      - ./hadoop-conf/core-site.xml:/etc/hadoop/core-site.xml
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.15
    extra_hosts:
      - "namenode:192.168.0.9"
    command: >
      bash -c "
        sleep 60 &&
        chmod +x /app/spark_producer.py &&
        spark-submit \
          --master spark://spark-master:7077 \
          --deploy-mode client \
          --driver-memory 1g \
          --executor-memory 1g \
          --executor-cores 2 \
          --jars /opt/spark-libs/kafka-clients-3.5.0.jar,/opt/spark-libs/spark-sql-kafka-0-10_2.12-3.5.0.jar,/opt/spark-libs/hadoop-client-3.3.4.jar \
          --files /etc/hadoop/core-site.xml \
          --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/etc/spark/log4j.properties \
          --conf spark.executor.extraJavaOptions=-Dlog4j.configuration=file:/etc/spark/log4j.properties \
          /app/spark_producer.py \
          --json-file /user/hadoop3/test.json \
          --kafka-brokers 192.168.0.12:9092,192.168.0.13:9093
      "
    restart: unless-stopped

  # Kafka to MongoDB Consumer
  kafka-mongo-consumer:
    build:
      context: .
      dockerfile: Dockerfile.consumer
    container_name: kafka-mongo-consumer
    depends_on:
      - kafka-1
      - mongodb-1
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=192.168.0.12:9092,192.168.0.13:9093
      - MONGO_HOST=mongodb
      - MONGO_PORT=27017
      - MONGO_DB=financial_db
      - MONGO_USER=admin
      - MONGO_PASSWORD=admin123
      - BATCH_SIZE=100
    volumes:
      - ./consumer-app:/app
    working_dir: /app
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.16
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "pgrep", "-f", "KafkaMongoConsumer"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MongoDB 클러스터 초기화 서비스 (일회성)
  mongodb-cluster-init:
    image: mongo:7.0
    container_name: mongodb-cluster-init
    depends_on:
      - mongodb-1
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=password123
    networks:
      hadoop-network:
        ipv4_address: 172.20.1.17
    command:
      - /bin/bash
      - -c
      - |
        echo 'Waiting for all MongoDB instances to be ready...'
        sleep 120  # DN4 MongoDB들이 시작될 시간을 충분히 대기
        
        # Primary 연결 시도
        echo 'Connecting to MongoDB Primary...'
        until mongosh --host 192.168.0.12:27017 -u admin -p password123 --authenticationDatabase admin --eval "db.runCommand({ping: 1})" > /dev/null 2>&1; do
          echo 'Waiting for Primary MongoDB...'
          sleep 10
        done
        
        # Secondary 연결 확인
        echo 'Checking Secondary MongoDB...'
        until nc -z 192.168.0.13 27018; do
          echo 'Waiting for Secondary MongoDB...'
          sleep 10
        done
        
        # Arbiter 연결 확인  
        echo 'Checking Arbiter MongoDB...'
        until nc -z 192.168.0.13 27019; do
          echo 'Waiting for Arbiter MongoDB...'
          sleep 10
        done
        
        echo 'All MongoDB instances are ready. Initializing replica set...'
        mongosh --host 192.168.0.12:27017 -u admin -p password123 --authenticationDatabase admin --eval "
          try {
            rs.initiate({
              _id: 'rs0',
              members: [
                { _id: 0, host: '192.168.0.12:27017', priority: 2 },
                { _id: 1, host: '192.168.0.13:27018', priority: 1 },
                { _id: 2, host: '192.168.0.13:27019', arbiterOnly: true }
              ]
            });
            print('Replica set initialized successfully');
          } catch (error) {
            if (error.code === 23) {
              print('Replica set already initialized');
            } else {
              print('Error initializing replica set: ' + error);
            }
          }
        "
        
        echo 'Waiting for primary election...'
        sleep 30
        
        # 레플리카셋 상태 확인
        mongosh --host 192.168.0.12:27017 -u admin -p password123 --authenticationDatabase admin --eval "
          print('Replica set status:');
          printjson(rs.status());
        "
        
        echo 'MongoDB cluster initialization completed'
    restart: "no"  # 일회성 실행
